{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02da167-f13e-4494-a81a-5d50dff61e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hirschsprung disease (HD) is considered multifactorial because its development is influenced by a combination of genetic, environmental, and possibly epigenetic factors. Here are the key reasons why it is classified this way:\n",
      "\n",
      "1. **Genetic Factors**: Hirschsprung disease is associated with mutations in several genes, most notably the RET proto-oncogene, which plays a crucial role in the development of the enteric nervous system. Variants in other genes, such as EDNRB, ECE1, and others, have also been implicated. However, not all individuals with these genetic mutations develop the disease, indicating that genetics alone do not determine the outcome.\n",
      "\n",
      "2. **Environmental Influences**: Environmental factors may also contribute to the risk of developing Hirschsprung disease. These can include maternal health conditions, exposure to certain drugs or toxins during pregnancy, and other prenatal factors that may affect fetal development.\n",
      "\n",
      "3. **Familial Patterns**: While Hirschsprung disease can occur sporadically, there is a recognized familial tendency, suggesting that a combination of inherited genetic predispositions and environmental triggers may play a role in its manifestation.\n",
      "\n",
      "4. **Complex Interactions**: The interplay between multiple genes and environmental factors can lead to variations in the severity and presentation of the disease. This complexity is characteristic of multifactorial conditions, where multiple pathways and influences converge to affect the phenotype.\n",
      "\n",
      "5. **Epigenetic Factors**: Emerging research suggests that epigenetic modifications, which can be influenced by environmental factors, may also play a role in the development of Hirschsprung disease. These modifications can affect gene expression without altering the underlying DNA sequence.\n",
      "\n",
      "In summary, the multifactorial nature of Hirschsprung disease arises from the interaction of genetic predispositions, environmental influences, and possibly epigenetic changes, making it a complex condition that cannot be attributed to a single cause.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "    \n",
    "response = client.chat.completions.create(\n",
    "    model= \"gpt-4.1-nano\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a medical research assistant for a BioASQ competition.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain why Hirschsprung disease is considered multifactorial.\"}\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f809fb7-0bca-4f77-a9c3-1a1b6eeb0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = \" \".join([s['text'] for s in first_q['snippets']])\n",
    "# prompt = f\"Context: {context}\\n\\nQuestion: {first_q['body']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40235965-450f-4f4d-bf07-38f32b921250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Batch file saved to: sample_batches/batch_20260212_225517_aa22f136.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import yaml\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Setup paths and directories\n",
    "BATCH_DIR = Path(\"sample_batches\")\n",
    "BATCH_DIR.mkdir(exist_ok=True)  # Creates the folder if it doesn't exist\n",
    "\n",
    "# 2. Get the current timestamp (sortable format)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 3. Load config and setup experiment hash\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "prompt_cfg = config['prompts']['ontology_builder']\n",
    "model_name = config['model']['deployment_name']\n",
    "exp_hash = hashlib.md5(f\"{model_name}_{prompt_cfg['system_prompt']}\".encode()).hexdigest()[:8]\n",
    "\n",
    "# 4. Define the final file name with timestamp\n",
    "batch_filename = BATCH_DIR / f\"batch_{timestamp}_{exp_hash}.jsonl\"\n",
    "\n",
    "# 5. Sample Data and Task Generation\n",
    "samples = [\n",
    "    {\"id\": \"s1\", \"text\": \"Hello world\"},\n",
    "    {\"id\": \"s2\", \"text\": \"Hi there\"}\n",
    "]\n",
    "\n",
    "tasks = []\n",
    "for item in samples:\n",
    "    task = {\n",
    "        \"custom_id\": f\"{exp_hash}_{item['id']}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt_cfg['system_prompt']},\n",
    "                {\"role\": \"user\", \"content\": item['text']}\n",
    "            ],\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "    tasks.append(task)\n",
    "\n",
    "# 6. Save to the new directory\n",
    "with open(batch_filename, \"w\") as f:\n",
    "    for t in tasks:\n",
    "        f.write(json.dumps(t) + \"\\n\")\n",
    "\n",
    "print(f\"üìÇ Batch file saved to: {batch_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e9c71a-8be5-45e7-826a-aa4d93aed281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload the file\n",
    "# batch_file_obj = client.files.create(\n",
    "#     file=open(batch_filename, \"rb\"),\n",
    "#     purpose=\"batch\"\n",
    "# )\n",
    "\n",
    "# # Create the batch\n",
    "# batch_job = client.batches.create(\n",
    "#     input_file_id=batch_file_obj.id,\n",
    "#     endpoint=\"/v1/chat/completions\",\n",
    "#     completion_window=\"24h\",\n",
    "#     metadata={\n",
    "#         \"experiment_id\": exp_id\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(f\"üöÄ Batch Job Created! ID: {batch_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88cc5588-57d0-4c6f-9261-fa5268e31ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_FILE = \"logs/batch_log.csv\"\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "def log_experiment(data_dict):\n",
    "    \"\"\"Appends experiment metadata to a CSV file.\"\"\"\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    if not os.path.isfile(LOG_FILE):\n",
    "        df.to_csv(LOG_FILE, index=False)\n",
    "    else:\n",
    "        df.to_csv(LOG_FILE, mode='a', header=False, index=False)\n",
    "\n",
    "def get_logged_experiments():\n",
    "    \"\"\"Returns the log as a DataFrame.\"\"\"\n",
    "    if os.path.isfile(LOG_FILE):\n",
    "        return pd.read_csv(LOG_FILE)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7940092-61fd-4f66-8264-863195b8da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_FILE = \"logs/batch_log.csv\"\n",
    "Path(\"logs\").mkdir(exist_ok=True)\n",
    "\n",
    "def log_experiment(data_dict):\n",
    "    \"\"\"Appends experiment metadata to a CSV file.\"\"\"\n",
    "    df = pd.DataFrame([data_dict])\n",
    "    if not os.path.isfile(LOG_FILE):\n",
    "        df.to_csv(LOG_FILE, index=False)\n",
    "    else:\n",
    "        df.to_csv(LOG_FILE, mode='a', header=False, index=False)\n",
    "\n",
    "def get_logged_experiments():\n",
    "    \"\"\"Returns the log as a DataFrame.\"\"\"\n",
    "    if os.path.isfile(LOG_FILE):\n",
    "        return pd.read_csv(LOG_FILE)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0035bb-9a17-4552-ba9d-768ac1d5354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "def submit_batch(samples, prompt_cfg, config):\n",
    "    client = OpenAI()\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    model_name = config['model']['deployment_name']\n",
    "    \n",
    "    # 1. Generate Idempotent Hash\n",
    "    sys_prompt = prompt_cfg['system_prompt']\n",
    "    exp_hash = hashlib.md5(f\"{model_name}_{sys_prompt}\".encode()).hexdigest()[:8]\n",
    "    exp_id = f\"{config['experiments']['active_id']}_{exp_hash}\"\n",
    "\n",
    "    # 2. Create the JSONL file\n",
    "    batch_path = Path(\"sample_batches\") / f\"batch_{exp_hash}_{datetime.now().strftime('%H%M%S')}.jsonl\"\n",
    "    batch_path.parent.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(batch_path, \"w\") as f:\n",
    "        for item in samples:\n",
    "            task = {\n",
    "                \"custom_id\": f\"{exp_id}_{item['id']}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\"model\": model_name, \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                    {\"role\": \"user\", \"content\": item['text']}\n",
    "                ], \"temperature\": 0}\n",
    "            }\n",
    "            f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "    # 3. Submit\n",
    "    file_obj = client.files.create(file=open(batch_path, \"rb\"), purpose=\"batch\")\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=file_obj.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\"\n",
    "    )\n",
    "\n",
    "    # 4. Log to CSV\n",
    "    log_experiment({\n",
    "        \"batch_id\": batch_job.id,\n",
    "        \"exp_id\": exp_id,\n",
    "        \"status\": \"in_progress\",\n",
    "        \"created_at\": timestamp,\n",
    "        \"model\": model_name,\n",
    "        \"system_prompt\": sys_prompt[:50] + \"...\", # Truncate for CSV readability\n",
    "        \"file_path\": str(batch_path),\n",
    "        \"output_file_id\": None,\n",
    "        \"input_tokens\": 0,\n",
    "        \"output_tokens\": 0\n",
    "    })\n",
    "    print(f\"üöÄ Submitted Batch: {batch_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59c402d-0cb3-4c04-abd4-5b3d32b33ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_and_download_results():\n",
    "    client = OpenAI()\n",
    "    logs = get_logged_experiments()\n",
    "    if logs.empty: return\n",
    "\n",
    "    updated = False\n",
    "    for idx, row in logs.iterrows():\n",
    "        if row['status'] not in ['completed', 'failed']:\n",
    "            job = client.batches.retrieve(row['batch_id'])\n",
    "            logs.at[idx, 'status'] = job.status\n",
    "            \n",
    "            if job.status == 'completed':\n",
    "                # Download and save the results\n",
    "                logs.at[idx, 'output_file_id'] = job.output_file_id\n",
    "                logs.at[idx, 'input_tokens'] = job.usage.input_tokens\n",
    "                logs.at[idx, 'output_tokens'] = job.usage.output_tokens\n",
    "                \n",
    "                # Fetch the actual JSONL content\n",
    "                content = client.files.content(job.output_file_id).text\n",
    "                result_path = Path(\"results\") / f\"results_{row['batch_id']}.jsonl\"\n",
    "                result_path.parent.mkdir(exist_ok=True)\n",
    "                \n",
    "                with open(result_path, \"w\") as f:\n",
    "                    f.write(content)\n",
    "                print(f\"‚úÖ Batch {row['batch_id']} COMPLETED. Results saved to {result_path}\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"‚è≥ Batch {row['batch_id']} is still {job.status}...\")\n",
    "            updated = True\n",
    "\n",
    "    if updated:\n",
    "        logs.to_csv(LOG_FILE, index=False)\n",
    "\n",
    "# Run this to check status\n",
    "sync_and_download_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cedfaa58-fe5b-493b-8bbd-892c326dd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_json(f\"results/results_{batch_id}.jsonl\", lines=True)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b9545-c586-470a-93dc-66a8898cc43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
